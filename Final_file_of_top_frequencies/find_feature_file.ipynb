{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_filenames(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_catalog = {}\n",
    "    \n",
    "    for root, directories, files in os.walk(directory):\n",
    "        text_file_names = [f for f in files if f.endswith(\".txt\")]\n",
    "        file_catalog[root]=text_file_names\n",
    "    return file_catalog  # Self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_top_frequency(list1 , filename):\n",
    "    n=len(list1)\n",
    "    list2=[]\n",
    "    list3=[]\n",
    "    if re.search('3_gram_final' , filename):\n",
    "        for i in range(n):\n",
    "            list2.append(int(list1[i]%1000000000))\n",
    "    if re.search('5_gram_final' , filename):\n",
    "        for i in range(n):\n",
    "            list2.append(int(list1[i]%1000000000000000))\n",
    "    if re.search('7_gram_final' , filename):\n",
    "        for i in range(n):\n",
    "            list2.append(int(list1[i]%1000000000000000000000))\n",
    "    for i in range(int((3*n)/10)):\n",
    "            list3.append(list2[i])\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countingSort(arr, exp1, n):\n",
    "    output = []\n",
    "    bucket=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    count = [0] * (10)\n",
    "    for i in range(n):\n",
    "        index = (arr[i]//exp1)%10\n",
    "        bucket[int(index)].append(arr[i])\n",
    "        \n",
    "    for i in range(10):\n",
    "        lenth=len(bucket[i])\n",
    "        for j in range(lenth):\n",
    "            output.append(bucket[i][j])\n",
    "    for i in range(n):\n",
    "        arr[i] = output[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def radixSort(arr):\n",
    "    max1 = max(arr)\n",
    "    exp = 1\n",
    "    n = len(arr)\n",
    "    while max1//exp > 0:\n",
    "        countingSort(arr,exp,n)\n",
    "        exp *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_got = get_filenames(r'C:\\Users\\Saket Agrawal\\Desktop\\File_of_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency_data_5_gram_Adduser_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Adduser_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Hydra_FTP_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Hydra_FTP_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Hydra_SSH_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Hydra_SSH_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Java_Meterpreter_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Java_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Meterpreter_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Normal_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Normal_gram_data.txt\n",
      "sss\n",
      "frequency_data_5_gram_Web_Shell_gram_data.txt\n",
      "5_gram_final_frequency_data_5_gram_Web_Shell_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Adduser_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Adduser_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Hydra_FTP_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Hydra_FTP_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Hydra_SSH_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Hydra_SSH_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Java_Meterpreter_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Java_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Meterpreter_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Normal_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Normal_gram_data.txt\n",
      "sss\n",
      "frequency_data_3_gram_Web_Shell_gram_data.txt\n",
      "3_gram_final_frequency_data_3_gram_Web_Shell_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Adduser_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Adduser_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Hydra_FTP_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Hydra_FTP_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Hydra_SSH_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Hydra_SSH_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Java_Meterpreter_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Java_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Meterpreter_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Meterpreter_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Normal_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Normal_gram_data.txt\n",
      "sss\n",
      "frequency_data_7_gram_Web_Shell_gram_data.txt\n",
      "7_gram_final_frequency_data_7_gram_Web_Shell_gram_data.txt\n",
      "sss\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sys import argv \n",
    "regex = ('[357]'+'_gram')\n",
    "for dir in file_got.keys() :\n",
    "    if re.search(regex, dir):\n",
    "        for file in file_got[dir] :\n",
    "            print(file)  \n",
    "            if re.search('3_gram' , dir):\n",
    "                filename='3_gram_final_'+file\n",
    "            if re.search('5_gram' , dir):\n",
    "                filename='5_gram_final_'+file\n",
    "            if re.search('7_gram' , dir):\n",
    "                filename='7_gram_final_'+file\n",
    "            print(filename)\n",
    "            print('sss')\n",
    "            concat = open(filename, 'a+')\n",
    "            buffer= open(dir+\"\\\\\"+file,'r')\n",
    "            list1=[]\n",
    "            for val in buffer.read().split():\n",
    "                list1.append(int(val))\n",
    "            buffer.close()\n",
    "            list_final=find_top_frequency(list1,filename)\n",
    "            radixSort(list_final)\n",
    "            if re.search('3_gram' , dir):\n",
    "                for item in list_final:\n",
    "                    concat.write(\"%s \" % int(item/1000000))\n",
    "                    concat.write(\"%s \" % int((item/1000)%1000))\n",
    "                    concat.write(\"%s\\n\" % int(item%1000))\n",
    "            if re.search('5_gram' , dir):\n",
    "                for item in list_final:\n",
    "                    concat.write(\"%s \" % int(item/1000000000000))\n",
    "                    concat.write(\"%s \" % int((item/1000000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000)%1000))\n",
    "                    concat.write(\"%s\\n\" % int(item%1000))\n",
    "            if re.search('7_gram' , dir):\n",
    "                for item in list_final:\n",
    "                    concat.write(\"%s \" % int(item/1000000000000000000))\n",
    "                    concat.write(\"%s \" % int((item/1000000000000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000000000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000000)%1000))\n",
    "                    concat.write(\"%s \" % int((item/1000)%1000))\n",
    "                    concat.write(\"%s\\n\" % int(item%1000))\n",
    "            concat.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
